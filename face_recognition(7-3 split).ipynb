{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c83bb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21be040a",
   "metadata": {},
   "source": [
    "# Generate Data Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5731367",
   "metadata": {},
   "source": [
    "The dataset consists of 40 persons each is referenced to by a folder called s#. Each folder for a person contains 10 different samples of grayscale pictures for this person producing a total number of 400 samples. Each sample is represented by a vector of 10304 elements (112x92)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf49b5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_persons = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbe9bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_single_image(image_path):\n",
    "    ans = []\n",
    "    with open(image_path, 'rb') as f:\n",
    "        assert f.readline() == b'P5\\n'\n",
    "        assert f.readline() == b'92 112\\n'\n",
    "        assert f.readline() == b'255\\n'        \n",
    "        for i in range(10304):\n",
    "            ans.append(ord(f.read(1)))\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e84232",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_data_frame():\n",
    "    images = []\n",
    "    persons = []\n",
    "    path = 'E:/Term 07/Pattern Recognition/Projects/Project 01/People/'\n",
    "    print('Reading Started')\n",
    "    for x in range(1, number_of_persons + 1):\n",
    "        current_person_path = path + 's' + str(x) + '/'\n",
    "        for y in range(1, 11):\n",
    "            persons.append(str(x))\n",
    "            images.append(read_single_image(current_person_path + str(y) + '.pgm'))\n",
    "    print('Reading Finished')\n",
    "    print('Number of Images loaded: ',len(images))\n",
    "    print('Size of Vector per Image: ',len(images[0]))\n",
    "    images = np.array(images)    \n",
    "    return images, persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77748c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(D, labels) = construct_data_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9b61f9",
   "metadata": {},
   "source": [
    "# Test-Train Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9b8784",
   "metadata": {},
   "source": [
    "The data matrix is divided into two equally divided matrices each with size 200x10304 one for testing and another for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe2f095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_train_test_split(data, labels, samples_no, train_indices):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for i in range(samples_no):\n",
    "        if i%10 in train_indices:\n",
    "            X_train.append(data[i])\n",
    "            y_train.append(labels[i])\n",
    "        else:\n",
    "            X_test.append(data[i])\n",
    "            y_test.append(labels[i])\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66f9c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = custom_train_test_split(D, labels, len(D), [0, 1, 3, 4, 6, 7, 9])\n",
    "train_data = pd.DataFrame(X_train,index=y_train)\n",
    "test_data = pd.DataFrame(X_test,index=y_test)\n",
    "print('Train Data\\n',train_data)\n",
    "print('Test Data\\n',test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88455e9",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc319c9a",
   "metadata": {},
   "source": [
    "The KNN classifier is created according to a specified value for K from these: 1, 3, 5, and 7. The classifier gets trained by the data and label matrices specified for training. Then, it uses the test data in order to predict the corresponding class then compare this output with the expected output to check the classifier's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c2c511",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(X_train, y_train, X_test, y_test, n_neighbors):\n",
    "    simple_classifier = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    simple_classifier.fit(X_train, y_train)\n",
    "    test_samples = len(X_test)\n",
    "    acc = 0\n",
    "    y_predict = []\n",
    "    for i in range(test_samples):\n",
    "        result = simple_classifier.predict([X_test[i]])\n",
    "        y_predict.append(result)\n",
    "        if result == y_test[i]:\n",
    "            acc += 1\n",
    "    acc /= test_samples\n",
    "    print(f'Acc at K = {n_neighbors}: {acc*100} %')\n",
    "    return acc, simple_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2932eeea",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924a457e",
   "metadata": {},
   "source": [
    "Mean Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf6f50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean(data):\n",
    "    return np.mean(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54c4220",
   "metadata": {},
   "source": [
    "Centering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d7c114",
   "metadata": {},
   "outputs": [],
   "source": [
    "def centeralize(data):\n",
    "    return data - calculate_mean(data).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e289946a",
   "metadata": {},
   "source": [
    "Covariance Matrix Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f27e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_covariance_matrix(data):\n",
    "    z = centeralize(data)\n",
    "    return (np.matmul(np.transpose(z), z)) / len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28f1511",
   "metadata": {},
   "source": [
    "Eigenvalues and Eigenvectors Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d131b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_eigen_vectors(data):\n",
    "    cov = calculate_covariance_matrix(data)\n",
    "    eig_values, eig_vectors = np.linalg.eigh(cov)\n",
    "    idx = eig_values.argsort()[::-1]   \n",
    "    eig_values = eig_values[idx]\n",
    "    eig_vectors = eig_vectors[:,idx]\n",
    "    return eig_values, eig_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cb46be",
   "metadata": {},
   "source": [
    "Fraction of Total Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d706f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dimensionality(alpha, eig_values):\n",
    "    s = np.sum(eig_values)\n",
    "    r = 0\n",
    "    i = 0\n",
    "    for value in eig_values: \n",
    "        r = r + value\n",
    "        i = i + 1\n",
    "        if ((r / s) >= alpha):\n",
    "            break\n",
    "    return i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41256ef8",
   "metadata": {},
   "source": [
    "Reducing Eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f84a4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_reduced_dimensions(alpha_values, eig_values):\n",
    "    reduced_dimensions = []\n",
    "    for alpha in alpha_values:\n",
    "        reduced_dimensions.append(dimensionality(alpha, eig_values))\n",
    "    return reduced_dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b850099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA(data, alpha_values):\n",
    "    eig_values, eig_vectors = calculate_eigen_vectors(data)\n",
    "    r = calculate_reduced_dimensions(alpha_values, eig_values)\n",
    "    return r, eig_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856bcfeb",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12da48e1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a = [0.8, 0.85, 0.9, 0.95]\n",
    "mean = calculate_mean(train_data)\n",
    "z = centeralize(train_data)\n",
    "r, eig_vectors = PCA(train_data, a)\n",
    "print(r)\n",
    "j = 0\n",
    "classifiers = []\n",
    "for i in r:\n",
    "    print('for Alpha = ',a[j],' : R = ',i,'\\n')\n",
    "    j += 1\n",
    "    U = eig_vectors[:,0:i]\n",
    "    projected_train_data = np.array(np.matmul(z, U))\n",
    "    projected_test_data = np.array(np.matmul(X_test - np.array(mean).T, U))\n",
    "    acc = []\n",
    "    k_values = [1, 3, 5, 7]\n",
    "    for k in k_values:\n",
    "        accuracy, classifier = classify(projected_train_data, y_train, projected_test_data, y_test, k)\n",
    "        acc.append(accuracy)\n",
    "        classifiers.append(classifier)\n",
    "    plt.plot(k_values, acc)\n",
    "    plt.xlabel('Number of neighbors')\n",
    "    plt.ylabel('Acc')\n",
    "    plt.title('K tunning graph')\n",
    "    plt.show()\n",
    "print('Number of Built Classifiers: ',len(classifiers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3cefa5",
   "metadata": {},
   "source": [
    "# Single Image Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce21be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(img,c,r):\n",
    "    U = eig_vectors[:,:r]\n",
    "    x = np.array(np.matmul(img - np.array(mean).T, U))\n",
    "    return c.predict([x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a479dd68",
   "metadata": {},
   "source": [
    "Tryin to test 16th image from the test matrix and using 11th classifier where (Alpha = 0.9, R = 55, K = 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8dc68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Predicted Class ',predict(X_test[15],classifiers[10],55))\n",
    "print('Expected Class ',y_test[15])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
